{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184eeb9b-2078-40cf-8d17-d01935671c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af03068b-b887-44b4-90ba-f03a59f7fdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.24s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 61268 tokens at 396509.72 tokens per second.\n",
      "PTBTokenizer tokenized 10892 tokens at 123661.94 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "Downloading stanford-corenlp-3.6.0 for SPICE ...\n",
      "Progress: 384.5M / 384.5M (100.0%)\n",
      "Extracting stanford-corenlp-3.6.0 ...\n",
      "Done.\n",
      "computing Bleu score...\n",
      "{'testlen': 9893, 'reflen': 9855, 'guess': [9893, 8893, 7893, 6893], 'correct': [5732, 2510, 1043, 423]}\n",
      "ratio: 1.003855910705124\n",
      "Bleu_1: 0.579\n",
      "Bleu_2: 0.404\n",
      "Bleu_3: 0.279\n",
      "Bleu_4: 0.191\n",
      "computing METEOR score...\n",
      "METEOR: 0.195\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.396\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.600\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/graham/mambaforge/envs/p310/lib/python3.10/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [19.221 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [2.621 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 28.87 s\n",
      "SPICE: 0.133\n",
      "Bleu_1: 0.579\n",
      "Bleu_2: 0.404\n",
      "Bleu_3: 0.279\n",
      "Bleu_4: 0.191\n",
      "METEOR: 0.195\n",
      "ROUGE_L: 0.396\n",
      "CIDEr: 0.600\n",
      "SPICE: 0.133\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "\n",
    "annotation_file = 'pycocoevalcap/example/captions_val2014.json'\n",
    "results_file = 'pycocoevalcap/example/captions_val2014_fakecap_results.json'\n",
    "\n",
    "# create coco object and coco_result object\n",
    "coco = COCO(annotation_file)\n",
    "coco_result = coco.loadRes(results_file)\n",
    "\n",
    "# create coco_eval object by taking coco and coco_result\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "# SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "coco_eval.evaluate()\n",
    "\n",
    "# print output evaluation scores\n",
    "for metric, score in coco_eval.eval.items():\n",
    "    print(f'{metric}: {score:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34eb3684-91cd-4c54-9609-9dbec8a191a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results/captions__fakecap_results.json'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa47a918-ced5-4e14-ae47-c6bb9f8e402f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "291c3c7b-c28e-4613-a254-e74eb6f59b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 307315 tokens at 1241513.19 tokens per second.\n",
      "PTBTokenizer tokenized 61641 tokens at 390669.99 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 52465, 'reflen': 52465, 'guess': [52465, 47465, 42465, 37465], 'correct': [52465, 47465, 42465, 37465]}\n",
      "ratio: 0.999999999999981\n",
      "Bleu_1: 1.000\n",
      "Bleu_2: 1.000\n",
      "Bleu_3: 1.000\n",
      "Bleu_4: 1.000\n",
      "computing METEOR score...\n",
      "METEOR: 1.000\n",
      "computing Rouge score...\n",
      "ROUGE_L: 1.000\n",
      "computing CIDEr score...\n",
      "CIDEr: 2.706\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/graham/mambaforge/envs/p310/lib/python3.10/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 4.259 s\n",
      "SPICE: 0.432\n",
      "Bleu_1: 1.000\n",
      "Bleu_2: 1.000\n",
      "Bleu_3: 1.000\n",
      "Bleu_4: 1.000\n",
      "METEOR: 1.000\n",
      "ROUGE_L: 1.000\n",
      "CIDEr: 2.706\n",
      "SPICE: 0.432\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "\n",
    "annotation_file = '/data/graham/datasets/coco/aokvqacoco/datasets/coco/annotations/captions_val2017.json'\n",
    "baseline_results_file = '/home/graham/code/torchtask/generalist/experiments/results/coco_val_baseline.json'\n",
    "# annotation_file = 'captions_val2014.json'\n",
    "# results_file = 'captions_val2014_fakecap_results.json'\n",
    "\n",
    "# create coco object and coco_result object\n",
    "coco = COCO(annotation_file)\n",
    "coco_result = coco.loadRes(baseline_results_file)\n",
    "\n",
    "# create coco_eval object by taking coco and coco_result\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "coco_eval.params[\"image_id\"] = coco_result.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "# SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "coco_eval.evaluate()\n",
    "\n",
    "# print output evaluation scores\n",
    "for metric, score in coco_eval.eval.items():\n",
    "    print(f\"{metric}: {score:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f86a4b19-72ec-456e-a186-d7d2aef2f09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 307315 tokens at 1166661.65 tokens per second.\n",
      "PTBTokenizer tokenized 98061 tokens at 604331.05 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 83467, 'reflen': 64245, 'guess': [83467, 78467, 73467, 68467], 'correct': [20346, 4142, 647, 207]}\n",
      "ratio: 1.29919838119696\n",
      "Bleu_1: 0.244\n",
      "Bleu_2: 0.113\n",
      "Bleu_3: 0.048\n",
      "Bleu_4: 0.024\n",
      "computing METEOR score...\n",
      "METEOR: 0.090\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.245\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.016\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/home/graham/mambaforge/envs/p310/lib/python3.10/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Parsing test captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [0.9 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.4 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Threads( StanfordCoreNLP ) [35.596 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 45.01 s\n",
      "SPICE: 0.024\n",
      "Bleu_1: 0.244\n",
      "Bleu_2: 0.113\n",
      "Bleu_3: 0.048\n",
      "Bleu_4: 0.024\n",
      "METEOR: 0.090\n",
      "ROUGE_L: 0.245\n",
      "CIDEr: 0.016\n",
      "SPICE: 0.024\n"
     ]
    }
   ],
   "source": [
    "# create coco object and coco_result object\n",
    "pred_results_file = '/home/graham/code/torchtask/generalist/experiments/results/coco_pred_results.json'\n",
    "coco = COCO(annotation_file)\n",
    "coco_result = coco.loadRes(pred_results_file)\n",
    "\n",
    "# create coco_eval object by taking coco and coco_result\n",
    "coco_eval = COCOEvalCap(coco, coco_result)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "coco_eval.params[\"image_id\"] = coco_result.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "# SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "coco_eval.evaluate()\n",
    "\n",
    "# print output evaluation scores\n",
    "for metric, score in coco_eval.eval.items():\n",
    "    print(f\"{metric}: {score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56482424-4b0e-4134-baf6-4af84a4ff1d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "COCO.showAnns() missing 1 required positional argument: 'anns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coco_result\u001b[38;5;241m.\u001b[39mshowAnns()\n",
      "\u001b[0;31mTypeError\u001b[0m: COCO.showAnns() missing 1 required positional argument: 'anns'"
     ]
    }
   ],
   "source": [
    "coco_result.showAnns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "651dfd2e-b30b-47a4-9496-31109d4dfc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coco_eval.params[\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7494b97-fa32-4cd5-b39b-a62da86b3f26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
